{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination of the face detection code with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # Draw rectangles around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Break the loop with the 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything is done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom face detection with optional webcam or ESP32 integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '-NvhZwmoZYw0R3Gli0Bt'}\n",
      "{'name': '-NvhZx-swF92j29mlpkX'}\n",
      "{'name': '-NvhZxCizKuRhSTCAVTp'}\n",
      "{'name': '-NvhZxNJZqI5ulwaB6MH'}\n",
      "{'name': '-NvhZxZmsEY7wDUraqXS'}\n",
      "{'name': '-NvhZxj4YsVx4kBqLapg'}\n",
      "{'name': '-NvhZxtS2k-TtVgVWYpj'}\n",
      "{'name': '-NvhZy2lUAHhU2kTllA6'}\n",
      "{'name': '-NvhZyCvDKFIwqKspWDf'}\n",
      "{'name': '-NvhZyNJhSJp-fcFB1xN'}\n",
      "{'name': '-NvhZyXYCKvfxVdDseAu'}\n",
      "{'name': '-NvhZyiKXpo5l2dwWvBe'}\n",
      "{'name': '-NvhZytjKbxveB3tvYU1'}\n",
      "{'name': '-NvhZz2zbaUy_Gz9RKKQ'}\n",
      "{'name': '-NvhZzDHGWLE7IV1hxA9'}\n",
      "{'name': '-NvhZzNVfd8ncwT9uE8K'}\n",
      "{'name': '-NvhZzXlz_O1tR9l8_LE'}\n",
      "{'name': '-NvhZzhCORfrZSrFv9JS'}\n",
      "{'name': '-NvhZzrdR4dYGDH_A1nq'}\n",
      "{'name': '-Nvh_-22L29FV73K7Kjq'}\n",
      "{'name': '-Nvh_-CpRE1aAYcatSgx'}\n",
      "{'name': '-Nvh_-N-aB5z66SU_fZj'}\n",
      "{'name': '-Nvh_-YRe-x9Lp_mT04H'}\n",
      "{'name': '-Nvh_-hVvm0_9o00X4NX'}\n",
      "{'name': '-Nvh_-tZ6fUJWr4_sXAh'}\n",
      "{'name': '-Nvh_03hrUWTfx7DKSdm'}\n",
      "{'name': '-Nvh_0HuB27Qesre4vFk'}\n",
      "{'name': '-Nvh_0SNtLxYo1yh6eVl'}\n",
      "{'name': '-Nvh_0ccnWtYgrhpVXkc'}\n",
      "{'name': '-Nvh_0mwvnJ8iM8ppZnl'}\n",
      "{'name': '-Nvh_0y-926MYuHYTejs'}\n",
      "{'name': '-Nvh_17c7W2g0J3_7wci'}\n",
      "{'name': '-Nvh_1JJ6fjmOqftcUaL'}\n",
      "{'name': '-Nvh_1W9rhRjMlfA8-at'}\n",
      "{'name': '-Nvh_1h1mny5zZ56PNJu'}\n",
      "{'name': '-Nvh_1saVCBzbGxErdwI'}\n",
      "{'name': '-Nvh_22k6n4RPTlHFGml'}\n",
      "{'name': '-Nvh_2EVTnWQcRZqPdUg'}\n",
      "{'name': '-Nvh_2PB-t6pBU01RJdz'}\n",
      "{'name': '-Nvh_2_HSqq06FckLNTz'}\n",
      "{'name': '-Nvh_2jd9uaDow8kq3Fk'}\n",
      "{'name': '-Nvh_2v0jzXS0lGhT4wG'}\n",
      "{'name': '-Nvh_34e90qFIGXOd812'}\n",
      "{'name': '-Nvh_3F4iCIafBE2GOH6'}\n",
      "{'name': '-Nvh_3QCTSo1BS9Hb77D'}\n",
      "{'name': '-Nvh_3ae0ucLjS3ONBOm'}\n",
      "{'name': '-Nvh_3n_OzExGKhEheyT'}\n",
      "{'name': '-Nvh_3wa5BxUO5wtsuxi'}\n",
      "{'name': '-Nvh_476jxBNRz7Q5IL2'}\n",
      "{'name': '-Nvh_4EmhEjOR1CzL8NT'}\n",
      "{'name': '-Nvh_4QSnKZp2kOiYnGZ'}\n",
      "{'name': '-Nvh_4YBpjcl6XVsOAIv'}\n",
      "{'name': '-Nvh_4if2_BMvIJNfgQV'}\n",
      "{'name': '-Nvh_4sMe15kyBMsnyhE'}\n",
      "{'name': '-Nvh_52DCH7_hGHhG7r_'}\n",
      "{'name': '-Nvh_5A6vEsyKa8TKVSv'}\n",
      "{'name': '-Nvh_5KHCD8vd4tZBlEV'}\n",
      "{'name': '-Nvh_5c_UV3mQD14LkEq'}\n",
      "{'name': '-Nvh_5myGHfh6DcpSSS7'}\n",
      "{'name': '-Nvh_5yQ3ZOYb4j6kCSs'}\n",
      "{'name': '-Nvh_6AFUzOWoSBeKx-U'}\n",
      "{'name': '-Nvh_6KYS_pZBbiXr8mp'}\n",
      "{'name': '-Nvh_6VVw8JLrUvIiCXk'}\n",
      "{'name': '-Nvh_6eXBx4XV9b2FS8f'}\n",
      "{'name': '-Nvh_6orHePwFinRg4hq'}\n",
      "{'name': '-Nvh_70Fl7GY2dBVxb7r'}\n",
      "{'name': '-Nvh_7BlQ14s9O_gmQNw'}\n",
      "{'name': '-Nvh_7M2rUlHT8MF_B48'}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import firebase_admin\n",
    "from firebase_admin import credentials, storage\n",
    "from firebase_admin import db\n",
    "import requests\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import firebase\n",
    "from firebase import firebase\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "\n",
    "# Load sample pictures and learn how to recognize them\n",
    "def load_known_faces(known_faces_dir='/add your directory here/faces'):\n",
    "    for name in os.listdir(known_faces_dir):\n",
    "        person_dir = os.path.join(known_faces_dir, name)\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(person_dir):\n",
    "            for filename in os.listdir(person_dir):\n",
    "                image_path = os.path.join(person_dir, filename)\n",
    "                # Check if the file is an image\n",
    "                if image_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image = face_recognition.load_image_file(image_path)\n",
    "                    # Sometimes you might get an image without any recognizable faces.\n",
    "                    # face_encodings function returns a list, and you should check if it's not empty.\n",
    "                    face_encodings = face_recognition.face_encodings(image)\n",
    "                    if face_encodings:\n",
    "                        encoding = face_encodings[0]\n",
    "                        known_face_encodings.append(encoding)\n",
    "                        known_face_names.append(name)\n",
    "\n",
    "# instance of function \n",
    "\n",
    "load_known_faces()\n",
    "\n",
    "# for webcam initialize set it to zero \n",
    "# Initialize the webcam\n",
    "# Initialize the ESP32-cam \n",
    "\n",
    "# setting ESP32 camera url server\n",
    "\n",
    "cam_url = \"http://192.168.1.7/cam-hi.jpg\"\n",
    "\n",
    "\n",
    "video_capture = cv2.VideoCapture(cam_url)\n",
    "\n",
    "video_capture.set(3, 640)\n",
    "video_capture.set(4, 480)\n",
    "\n",
    "firebase = firebase.FirebaseApplication('https://ecocleaner-3222b-default-rtdb.firebaseio.com/', None)\n",
    "\n",
    "# check if the hit is successful\n",
    "trigger = firebase.get('/ecocleaner-3222b-default-rtdb', None)\n",
    "if trigger == 1:\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        # ret, frame = video_capture.read()\n",
    "        # # Load an image from the webcam and locate the faces\n",
    "\n",
    "\n",
    "        img_resp = urllib.request.urlopen(cam_url)\n",
    "        imgnp = np.array(bytearray(img_resp.read()), dtype=np.uint8)\n",
    "        im = cv2.imdecode(imgnp, -1)\n",
    "\n",
    "        \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(im)\n",
    "        face_encodings = face_recognition.face_encodings(im, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        \n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known faces\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "\n",
    "            # the default name value should appear if find not similar face which will be sent to the database as unkown\n",
    "            name = \"unknown\" # set defualt to unknown\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                # updating the name from 'unknown' to the best match name\n",
    "                name = known_face_names[best_match_index]\n",
    "                \n",
    "            # time.sleep(30)\n",
    "            face_names.append(name)\n",
    "\n",
    "            \n",
    "            final_results = firebase.post('/ecocleaner-3222b-default-rtdb', face_names)\n",
    "            print(final_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Display the results\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            # Draw a box around the face\n",
    "            cv2.rectangle(im, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            # Draw a label with a name below the face\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(im, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "            # sending the outout to the database just after catching the name \n",
    "            \n",
    "            ## it fails here with this logic \n",
    "\n",
    "            # we will try here to send the output to the database\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow('Video', im)\n",
    "\n",
    "        # Hit 'q' on the keyboard to quit!\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close windows\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
